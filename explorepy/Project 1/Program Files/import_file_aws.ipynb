{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lamida Function To push the file from one bucket to another as soon as it is inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # Initialize S3 client\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        # Extract bucket name and object key from the event\n",
    "        source_bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "        source_key = event['Records'][0]['s3']['object']['key']\n",
    "        \n",
    "        # Define destination bucket and key\n",
    "        destination_bucket = 'zishtacoretransit-1'\n",
    "        for _ in range(3):  # Retry up to 3 times\n",
    "            try:\n",
    "                # Copy the object to the destination bucket\n",
    "                copy_source = {'Bucket': source_bucket, 'Key': source_key}\n",
    "                s3.copy_object(CopySource=copy_source, Bucket=destination_bucket, Key=source_key)\n",
    "\n",
    "                print(f\"File copied from {source_bucket}/{source_key} to {destination_bucket}/{source_key}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                raise e\n",
    "        else:\n",
    "                raise Exception(\"Max retries reached. File not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        raise e\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fetch the data using read_sql_table  which can be only used only after installing sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by using sqlalchemy we can get the data forread_sql_table\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "psycho_connect = create_engine('postgresql+psycopg2://postgres:log@localhost/zishta2024dump')\n",
    "items_df = pd.read_sql_table('item',psycho_connect,schema='zishta2024')\n",
    "print(items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an engine\n",
    "engine = create_engine('postgresql://postgres:log@localhost/zishta2024dump')\n",
    "# Execute a query and load data into a DataFrame\n",
    "df = pd.read_sql_query(\"SELECT * FROM zishta2024.item\", engine)\n",
    "# Print DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*converting a list into string using comprehencian method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_column= ['itemid', 'cancel', 'modifiedon', 'createdon','company', 'transid', 'itemdesc',\n",
    "               'itemcode', 'item_hsn', 'taxcategorycode', 'taxrate',  'active',  'itemname','sellingunit', 'stdcost', 'mrp',\n",
    "                 'zishtaitemcode',  'comboitem','stdsellingprice', 'shopify_id', 'itemcategoryid', 'itemcategory',\n",
    "                  'productcategory', 'hsnno', 'purchaseac','amazonitemcode', 'amazon_code']\n",
    "\n",
    "val = ''.join('a.'+i.strip('')+',' for i in req_column)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_msg =\"\"\" \n",
    "Dear Asperients, \n",
    "\n",
    "I am pleased to inform you that the job has been successfully executed. \n",
    "\n",
    "Best regards, \n",
    "Venkatesh. \"\"\"\n",
    "\n",
    "Failure_message =\"\"\" \n",
    "Dear Asperients, \n",
    "\n",
    "I am pleased to inform you that the job has been successfully executed. \n",
    "\n",
    "Best regards, \n",
    "Venkatesh. \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Email Configuration to send notification for the specific event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "def trigger_the_mail(message):\n",
    "    with open(r'C:\\Users\\user\\pythontest\\explorepy\\Project 1\\DataSet\\email_pwd.json','r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "\n",
    "    from_address = json_data['Details'][0][\"email\"]\n",
    "    to_address = [j[\"Email\"] for j in json_data['Details'][1::]]\n",
    "    subject = \"Job Status Notification!\"\n",
    "    body = message\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = from_address\n",
    "    msg['To'] = ', '.join([j[\"Email\"] for j in json_data['Details'][1::]]) \n",
    "    msg['Subject'] = subject\n",
    "    msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "    smtp_server = 'smtp.gmail.com'\n",
    "    smtp_port = 587\n",
    "    smtp_user = json_data['Details'][0][\"email\"]\n",
    "    smtp_password = json_data['Details'][0][\"password\"]\n",
    "\n",
    "    try:\n",
    "        server = smtplib.SMTP(smtp_server, smtp_port)\n",
    "        server.starttls()\n",
    "        server.login(smtp_user, smtp_password)\n",
    "        text = msg.as_string()\n",
    "        for new_mail in to_address:\n",
    "            server.sendmail(from_address, new_mail, text)\n",
    "        print(\"Email sent successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "jsonpath  = pd.read_json(r'C:\\Users\\user\\pythontest\\explorepy\\Project 1\\DataSet\\email_pwd.json')\n",
    "df = pd.DataFrame(jsonpath)\n",
    "\n",
    "with open(r'C:\\Users\\user\\pythontest\\explorepy\\Project 1\\DataSet\\email_pwd.json','r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "[j[\"Email\"] for j in json_data['Details'][1::]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptography.fernet import Fernet\n",
    "\n",
    "# Load the key from the file\n",
    "with open('secret.key', 'rb') as key_file:\n",
    "    key = key_file.read()\n",
    "\n",
    "cipher_suite = Fernet(key)\n",
    "\n",
    "# Decrypt the password\n",
    "encrypted_password = b'gAAAAABnfixQzPj8mdStxPKMzlmwT1UIGIo1BjHEshtx0JedMB7JfXlOdmQ6Pf13736NK2Mt0bHlEJpJ5K6DYtbQugTCce0kSc1eufIDAlWdO9JjjMmV7Kw='.decode()\n",
    "decrypted_password = cipher_suite.decrypt(encrypted_password)\n",
    "print(\"Decrypted password:\", decrypted_password.decode())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create a Insert script for log in postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from datetime import datetime\n",
    "\n",
    "connect_todb = psycopg2.connect(\n",
    "    host = 'localhost',\n",
    "    database = 'zishta2024dump',\n",
    "    user = 'postgres',\n",
    "    password = 'log',\n",
    "    port = 5432\n",
    ")\n",
    "schema = 'zishta2024'\n",
    "extract_query = connect_todb.cursor()\n",
    "from psycopg2 import sql        #importing Sql Module from psycopg2 liberary\n",
    "insert_intolog = sql.SQL('insert into zishta2024.job_log(id,job_name,status,message,success) values(%s,%s,%s,%s,%s)')\n",
    "extract_query.execute(insert_intolog,('SQ'+datetime.now().strftime('%d%m%y%H%M%S'),'Success trigger.','Success',f\"Job Succesfully completed at {datetime.now().strftime('%d%m%y%H%M%S')}\",'T'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record inserted successfully into job_log table!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from datetime import datetime\n",
    "from psycopg2 import sql\n",
    "\n",
    "try:\n",
    "    # Connect to the database\n",
    "    connect_todb = psycopg2.connect(\n",
    "        host='localhost',\n",
    "        database='zishta2024dump',\n",
    "        user='postgres',\n",
    "        password='log',\n",
    "        port=5432\n",
    "    )\n",
    "    \n",
    "    # Create a cursor object\n",
    "    extract_query = connect_todb.cursor()\n",
    "    \n",
    "    # SQL insert statement\n",
    "    insert_intolog = sql.SQL('''\n",
    "        INSERT INTO zishta2024.job_log (id, job_name, status, message, success)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    ''')\n",
    "    \n",
    "    # Values to insert\n",
    "    id = f\"SQ{datetime.now().strftime('%d%m%y%H%M%S')}\"\n",
    "    job_name = 'Success trigger.'\n",
    "    status = 'Success'\n",
    "    message = f\"Job Successfully completed at {datetime.now().strftime('%d%m%y%H%M%S')}\"\n",
    "    success = 'T'\n",
    "    \n",
    "    # Execute the insert statement\n",
    "    extract_query.execute(insert_intolog, (id, job_name, status, message, success))\n",
    "    \n",
    "    # Commit the transaction\n",
    "    connect_todb.commit()\n",
    "    \n",
    "    print(\"Record inserted successfully into job_log table!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    \n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    if extract_query:\n",
    "        extract_query.close()\n",
    "    if connect_todb:\n",
    "        connect_todb.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
